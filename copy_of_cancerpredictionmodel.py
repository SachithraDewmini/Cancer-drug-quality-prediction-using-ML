# -*- coding: utf-8 -*-
"""Copy of CancerPredictionModel.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1sGsalsAVlP0WZWWASIBOyS-EnRnzW5zz
"""

from google.colab import drive
drive.mount('/content/drive')

# Import necessary libraries
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import warnings
# Ignore warnings
warnings.filterwarnings('ignore')

from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score

# Importing the dataset and reading it into a DataFrame
path = '/content/drive/MyDrive/Cancer_Prediction/Cancer_Data.csv'

cancer_data = pd.read_csv(path)

# Display all columns of the DataFrame
pd.set_option('display.max_columns', None)
# Display the first few rows of the dataset
cancer_data.head()

# Drop the 'id' column as it is not needed for the analysis
cancer_data.drop('id', axis=1, inplace=True)

# Encode the 'diagnosis' column (B -> 0, M -> 1)
from sklearn.preprocessing import LabelEncoder
le= LabelEncoder()
cancer_data['diagnosis']= le.fit_transform(cancer_data['diagnosis'])

# Display the first few rows after encoding
cancer_data.head()

# Display the normalized value counts of the 'diagnosis' column
cancer_data['diagnosis'].value_counts(normalize= True)

# Display information about the dataset
cancer_data.info()

# Display the value counts of a specified column
cancer_data['diagnosis'].value_counts()

# Drop the 'Unnamed: 32' column as it is not needed for the analysis
if 'Unnamed: 32' in cancer_data.columns:
    cancer_data.drop('Unnamed: 32', axis=1, inplace=True)
else:
    print("Column 'Unnamed: 32' does not exist in the DataFrame.")

# Display the columns of the dataset
cancer_data.columns

# Display the shape of the dataset
cancer_data.shape
# Display the summary statistics of the dataset
cancer_data.describe()

# Check for duplicate rows
cancer_data.duplicated().sum()

# Compute and display the correlation matrix of selected columns with a heatmap
cancer_data[['diagnosis', 'radius_mean', 'texture_mean', 'perimeter_mean',
       'area_mean', 'smoothness_mean', 'compactness_mean', 'concavity_mean',
       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean',
       'radius_se', 'texture_se', 'perimeter_se', 'area_se', 'smoothness_se',
       'compactness_se', 'concavity_se', 'concave points_se', 'symmetry_se',
       'fractal_dimension_se', 'radius_worst', 'texture_worst',
       'perimeter_worst', 'area_worst', 'smoothness_worst',
       'compactness_worst', 'concavity_worst', 'concave points_worst',
       'symmetry_worst', 'fractal_dimension_worst']].corr().style.background_gradient(cmap='coolwarm')

# Select relevant columns and compute the correlation matrix with a heatmap
relevant= cancer_data[['diagnosis', 'fractal_dimension_mean', 'concave points_worst', 'radius_worst','perimeter_worst',	'area_worst', 'perimeter_mean', 'area_mean', 'radius_mean' ]]
relevant.corr().style.background_gradient(cmap='coolwarm')

# Define features (X) and target (y)
X= cancer_data[['fractal_dimension_mean', 'concave points_worst', 'perimeter_worst']]
y= cancer_data['diagnosis']

# Split the dataset into training and testing sets
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
X_train, X_test, y_train, y_test= train_test_split(X, y, test_size= 0.3, random_state= 42)
# Standardize the features
scx= StandardScaler()
X_train_scled= scx.fit_transform(X_train)
X_test_scled= scx.transform(X_test)

# Train a logistic regression model
from sklearn.linear_model import LogisticRegression
lr= LogisticRegression()
lr.fit(X_train_scled, y_train)
# Make predictions on the test set
y_pred= lr.predict(X_test_scled)
y_pred

# Compute the accuracy score
from sklearn.metrics import accuracy_score, confusion_matrix
accuracy_score(y_test, y_pred)

# Display the confusion matrix with a heatmap
cm= pd.DataFrame(confusion_matrix(y_test, y_pred))
sns.heatmap(cm, annot=True, fmt='d', cmap='Reds')
plt.xlabel('Predicted')
plt.ylabel('Actual')
plt.show()

# Display the last few rows of the dataset
cancer_data.tail()

# Predict the class of a new sample
print(lr.predict(scx.transform([[0.05648, 0.1418, 126.70 ]])))

# Display all rows where diagnosis is 0 (Benign)
cancer_data[cancer_data['diagnosis']==0]

# Predict the class of another new sample
print(lr.predict(scx.transform([[0.06503, 0.02564, 57.26]])))